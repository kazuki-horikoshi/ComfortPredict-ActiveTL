{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries and model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 06:13:46.223453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 06:13:46.449217: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-12 06:13:46.495211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-12 06:13:46.495225: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-12 06:13:47.497490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-12 06:13:47.497606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-12 06:13:47.497611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "random.seed(1)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Define model hyperparameters\n",
    "parser = argparse.ArgumentParser(description='CNN-LSTM Base Model')\n",
    "parser.add_argument('--input_size', type=int, default=4) #modify from 7 due to reducing outdoor temp/RH and NV\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "parser.add_argument('--input_features', type=list, default=['Indoor Temp',\n",
    "                                                            'Indoor Humidity',\n",
    "                                                            'Air Velocity',\n",
    "                                                            'Globe Temperature'])\n",
    "\n",
    "parser.add_argument('--experiment', type=str, default='mode_random') \n",
    "# choose either 'condition_random', 'mode_random', 'mode_al'\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "mode_mapping = {'AC':0, 'NV':1}\n",
    "thermalpref_mapping = {'No Change':0, 'Warmer':1, 'Cooler':2}\n",
    "thermalacc_mapping = {'Acceptable':0, 'Unacceptable':1}\n",
    "airpref_mapping = {'No Change':0, 'More':1, 'Less':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load training/eval/test data from ASHRAE dataset\n",
    "thermalpref_df = pd.read_csv('../data/ashrae_thermalpref_sampled_data.csv')\n",
    "thermalacc_df = pd.read_csv('../data/ashrae_thermalacc_sampled_data.csv')\n",
    "airpref_df = pd.read_csv('../data/ashrae_airpref_sampled_data.csv')\n",
    "\n",
    "# # load training data from BCA dataset\n",
    "# if args.experiment == 'condition_random':\n",
    "#     thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_condition_random_data.csv')\n",
    "#     thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_condition_random_data.csv')\n",
    "#     airpref_train = pd.read_csv('../data/bca_airpref_train_condition_random_data.csv')\n",
    "# elif args.experiment == 'mode_random':\n",
    "#     thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_random_data.csv')\n",
    "#     thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_random_data.csv')\n",
    "#     airpref_train = pd.read_csv('../data/bca_airpref_train_mode_random_data.csv')\n",
    "# elif args.experiment == 'mode_al':\n",
    "#     thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_al_data.csv')\n",
    "#     thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_al_data.csv')\n",
    "#     airpref_train = pd.read_csv('../data/bca_airpref_train_mode_al_data.csv')\n",
    "# else:\n",
    "#     raise ValueError(f\"Experiment {args.experiment} is not supported.\")\n",
    "\n",
    "# # load test data from BCA dataset\n",
    "# thermalpref_test = pd.read_csv('../data/bca_thermalpref_test_data.csv')\n",
    "# thermalacc_test = pd.read_csv('../data/bca_thermalacc_test_data.csv')\n",
    "# airpref_test = pd.read_csv('../data/bca_airpref_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_split_data(df, target_col, test_size=0.2, eval_size=0.1):\n",
    "    \"\"\"\n",
    "    Splits the dataset into train, evaluation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "        df: The entire dataframe containing features and target column.\n",
    "        target_col: The name of the target column in the dataframe.\n",
    "        test_size: The proportion of the dataset to include in the test split.\n",
    "        eval_size: The proportion of the dataset to include in the eval split.\n",
    "\n",
    "    Returns:\n",
    "        train_df, eval_df, test_df: Three dataframes for training, evaluation, and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the dataframe for rows where 'Mode' is 'AC'\n",
    "    filtered_df = df[df['Mode'] == 'AC']\n",
    "    \n",
    "    # Split df into train+eval and test\n",
    "    train_eval_df, test_df = train_test_split(df, test_size=test_size, stratify=df[target_col])\n",
    "\n",
    "    # Further split train+eval into train and eval\n",
    "    train_df, eval_df = train_test_split(train_eval_df, test_size=eval_size / (1 - test_size), stratify=train_eval_df[target_col])\n",
    "\n",
    "    return train_df, eval_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by 'Mode' == 'AC' and split the dataframes\n",
    "thermalpref_train, thermalpref_eval, thermalpref_test = filter_and_split_data(thermalpref_df, target_col='Thermal Preference')\n",
    "thermalacc_train, thermalacc_eval, thermalacc_test = filter_and_split_data(thermalacc_df, target_col='Thermal Acceptability')\n",
    "airpref_train, airpref_eval, airpref_test = filter_and_split_data(airpref_df, target_col='Air Movement Preference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform label mapping\n",
    "thermalpref_train['Thermal Preference'] = thermalpref_train['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "thermalpref_eval['Thermal Preference'] = thermalpref_eval['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "thermalpref_test['Thermal Preference'] = thermalpref_test['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "\n",
    "thermalacc_train['Thermal Acceptability'] = thermalacc_train['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "thermalacc_eval['Thermal Acceptability'] = thermalacc_eval['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "thermalacc_test['Thermal Acceptability'] = thermalacc_test['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "\n",
    "airpref_train['Air Movement Preference'] = airpref_train['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "airpref_eval['Air Movement Preference'] = airpref_eval['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "airpref_test['Air Movement Preference'] = airpref_test['Air Movement Preference'].apply(lambda x: airpref_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_model_architecture(num_classes):\n",
    "    \"\"\"\n",
    "    Defines the CNN LSTM model architecture with model parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        num_classes: An integer value indicating the number of output classes for the model.\n",
    "        \n",
    "    Return:\n",
    "        model: The Keras object containing the CNN LSTM model architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Convolutional Layer (Part of the model to be retrained)\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same', input_shape=(args.input_size, 1), trainable=True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Two LSTM Layers (Part of the model to be retrained)\n",
    "    model.add(LSTM(256, return_sequences=True, recurrent_dropout=0.1, trainable=True))\n",
    "    model.add(LSTM(256, return_sequences=False, recurrent_dropout=0.1, trainable=True))\n",
    "\n",
    "    # Flatten the output from LSTM layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Two Dense (Fully Connected) Layers (These layers will remain fixed)\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "\n",
    "    # Output Layer (Part of the model to be retrained)\n",
    "    model.add(Dense(num_classes, activation='softmax', trainable=True))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_df, eval_df, model_name, target_col, num_classes):\n",
    "    # Assuming train_df has columns for features and a 'target' column for labels\n",
    "    X_train = np.array(train_df[args.input_features])\n",
    "    y_train = np.array(train_df[target_col])\n",
    "    \n",
    "    X_val = np.array(eval_df[args.input_features])\n",
    "    y_val = np.array(eval_df[target_col])\n",
    "\n",
    "    # Create and fit a Min-Max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss\n",
    "        patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True  # Restore the best model weights when training stops\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_scaled, \n",
    "                        y_train, \n",
    "                        epochs=args.num_epochs, \n",
    "                        batch_size=args.batch_size,\n",
    "                        validation_data=(X_val_scaled, y_val), \n",
    "                        callbacks=[checkpoint_callback, early_stopping_callback])\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "    print(history)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "def evaluate_model(model, test_df, scaler, model_name, target_col, metrics=['accuracy', 'weighted_f1']):\n",
    "    # Assuming test_df has columns for features and a 'target' column for labels\n",
    "    X_test = np.array(test_df[args.input_features])\n",
    "    y_true = np.array(test_df[target_col])\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    loaded_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "    \n",
    "    # Apply numerical scaler on X_test\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    y_pred = loaded_model.predict(X_test_scaled)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    if 'accuracy' in metrics:\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        evaluation_results['accuracy'] = accuracy\n",
    "\n",
    "    if 'weighted_f1' in metrics:\n",
    "        weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "        evaluation_results['weighted_f1'] = weighted_f1\n",
    "\n",
    "    return evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def train_model(model, train_df, model_name, target_col, num_classes):\n",
    "#     # Assuming train_df has columns for features and a 'target' column for labels\n",
    "#     X = np.array(train_df[args.input_features])\n",
    "#     y = np.array(train_df[target_col])\n",
    "\n",
    "#     # Split the data into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "#     # Create and fit a Min-Max scaler\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Convert labels to one-hot encoding\n",
    "#     y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "#     y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "#     # Define a callback to save the best model during training\n",
    "#     checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "    \n",
    "#     # Early stopping callback\n",
    "#     early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',  # Monitor validation loss\n",
    "#         patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "#         restore_best_weights=True  # Restore the best model weights when training stops\n",
    "#     )\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_scaled, \n",
    "#                         y_train, \n",
    "#                         epochs=args.num_epochs, \n",
    "#                         batch_size=args.batch_size,\n",
    "#                         validation_data=(X_val_scaled, y_val), \n",
    "#                         callbacks=[checkpoint_callback])\n",
    "\n",
    "#     # Save the final trained model\n",
    "#     model.save(model_name + '.h5')\n",
    "    \n",
    "#     print(history)\n",
    "\n",
    "#     return model, scaler\n",
    "\n",
    "# def evaluate_model(model, test_df, scaler, model_name, target_col, metrics=['accuracy', 'weighted_f1']):\n",
    "#     # Assuming test_df has columns for features and a 'target' column for labels\n",
    "#     X_test = np.array(test_df[args.input_features])\n",
    "#     y_true = np.array(test_df[target_col])\n",
    "\n",
    "#     # Load the pre-trained model\n",
    "#     loaded_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "    \n",
    "#     # Apply numerical scaler on X_test\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     # Get predictions from the model\n",
    "#     y_pred = loaded_model.predict(X_test_scaled)\n",
    "#     y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#     evaluation_results = {}\n",
    "\n",
    "#     if 'accuracy' in metrics:\n",
    "#         accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "#         evaluation_results['accuracy'] = accuracy\n",
    "\n",
    "#     if 'weighted_f1' in metrics:\n",
    "#         weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "#         evaluation_results['weighted_f1'] = weighted_f1\n",
    "\n",
    "#     return evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Preference Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 13:10:30.177282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-08-11 13:10:30.177728: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-11 13:10:30.177752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7bde9dfab31b): /proc/driver/nvidia/version does not exist\n",
      "2024-08-11 13:10:30.178731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1032 - accuracy: 0.0659 - val_loss: 1.0897 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.0887 - accuracy: 0.5055 - val_loss: 1.0765 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0739 - accuracy: 0.5055 - val_loss: 1.0542 - val_accuracy: 0.5652\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.0499 - accuracy: 0.5055 - val_loss: 1.0275 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0211 - accuracy: 0.5055 - val_loss: 0.9957 - val_accuracy: 0.5652\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9839 - accuracy: 0.5055 - val_loss: 0.9669 - val_accuracy: 0.5652\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9425 - accuracy: 0.5055 - val_loss: 0.9492 - val_accuracy: 0.5652\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9029 - accuracy: 0.5055 - val_loss: 0.9406 - val_accuracy: 0.5652\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8600 - accuracy: 0.5055 - val_loss: 0.9709 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8447 - accuracy: 0.4835 - val_loss: 1.0437 - val_accuracy: 0.3478\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8792 - accuracy: 0.4396 - val_loss: 1.0316 - val_accuracy: 0.3478\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8695 - accuracy: 0.4835 - val_loss: 1.0129 - val_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8704 - accuracy: 0.5055 - val_loss: 1.0011 - val_accuracy: 0.5652\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8695 - accuracy: 0.5055 - val_loss: 0.9817 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8505 - accuracy: 0.6264 - val_loss: 0.9701 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8443 - accuracy: 0.5714 - val_loss: 0.9518 - val_accuracy: 0.6087\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8387 - accuracy: 0.5604 - val_loss: 0.9264 - val_accuracy: 0.6522\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8351 - accuracy: 0.6154 - val_loss: 0.9086 - val_accuracy: 0.6522\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8318 - accuracy: 0.6374 - val_loss: 0.8998 - val_accuracy: 0.6522\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8366 - accuracy: 0.5165 - val_loss: 0.8942 - val_accuracy: 0.6087\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8353 - accuracy: 0.6044 - val_loss: 0.8911 - val_accuracy: 0.6522\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8302 - accuracy: 0.6374 - val_loss: 0.8941 - val_accuracy: 0.6522\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8267 - accuracy: 0.6044 - val_loss: 0.8956 - val_accuracy: 0.6522\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8211 - accuracy: 0.6044 - val_loss: 0.8886 - val_accuracy: 0.6522\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8143 - accuracy: 0.6044 - val_loss: 0.8747 - val_accuracy: 0.6522\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8124 - accuracy: 0.6264 - val_loss: 0.8681 - val_accuracy: 0.6522\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8143 - accuracy: 0.6264 - val_loss: 0.8671 - val_accuracy: 0.6522\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8117 - accuracy: 0.6484 - val_loss: 0.8729 - val_accuracy: 0.6522\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8060 - accuracy: 0.6264 - val_loss: 0.8736 - val_accuracy: 0.6522\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8123 - accuracy: 0.6044 - val_loss: 0.8591 - val_accuracy: 0.6522\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8053 - accuracy: 0.6264 - val_loss: 0.8506 - val_accuracy: 0.6522\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8066 - accuracy: 0.6484 - val_loss: 0.8482 - val_accuracy: 0.6522\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7975 - accuracy: 0.6264 - val_loss: 0.8502 - val_accuracy: 0.6522\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7955 - accuracy: 0.6484 - val_loss: 0.8409 - val_accuracy: 0.6522\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7921 - accuracy: 0.6374 - val_loss: 0.8386 - val_accuracy: 0.6522\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7947 - accuracy: 0.6374 - val_loss: 0.8412 - val_accuracy: 0.6522\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7826 - accuracy: 0.6484 - val_loss: 0.8453 - val_accuracy: 0.6522\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7864 - accuracy: 0.6154 - val_loss: 0.8344 - val_accuracy: 0.6522\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7784 - accuracy: 0.6484 - val_loss: 0.8332 - val_accuracy: 0.6522\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7806 - accuracy: 0.6264 - val_loss: 0.8357 - val_accuracy: 0.6522\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7740 - accuracy: 0.6484 - val_loss: 0.8293 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7686 - accuracy: 0.6374 - val_loss: 0.8373 - val_accuracy: 0.6522\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7839 - accuracy: 0.6154 - val_loss: 0.8559 - val_accuracy: 0.6522\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8064 - accuracy: 0.6044 - val_loss: 0.9584 - val_accuracy: 0.6522\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8573 - accuracy: 0.6044 - val_loss: 0.8773 - val_accuracy: 0.6522\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7937 - accuracy: 0.6044 - val_loss: 0.8972 - val_accuracy: 0.5652\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8375 - accuracy: 0.5385 - val_loss: 0.8777 - val_accuracy: 0.5652\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8176 - accuracy: 0.5714 - val_loss: 0.8582 - val_accuracy: 0.6522\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7736 - accuracy: 0.6044 - val_loss: 0.9225 - val_accuracy: 0.6522\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8287 - accuracy: 0.6044 - val_loss: 0.9027 - val_accuracy: 0.6522\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8032 - accuracy: 0.6044 - val_loss: 0.8607 - val_accuracy: 0.6522\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7708 - accuracy: 0.6044 - val_loss: 0.8590 - val_accuracy: 0.7826\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7852 - accuracy: 0.6593 - val_loss: 0.8672 - val_accuracy: 0.6087\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7884 - accuracy: 0.6154 - val_loss: 0.8554 - val_accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7831 - accuracy: 0.6703 - val_loss: 0.8508 - val_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7711 - accuracy: 0.6264 - val_loss: 0.8634 - val_accuracy: 0.6522\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7751 - accuracy: 0.6044 - val_loss: 0.8759 - val_accuracy: 0.6522\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7835 - accuracy: 0.6044 - val_loss: 0.8697 - val_accuracy: 0.6522\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7884 - accuracy: 0.6044 - val_loss: 0.8542 - val_accuracy: 0.6522\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7762 - accuracy: 0.6264 - val_loss: 0.8457 - val_accuracy: 0.6957\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7635 - accuracy: 0.6703 - val_loss: 0.8498 - val_accuracy: 0.7826\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7803 - accuracy: 0.6813 - val_loss: 0.8471 - val_accuracy: 0.7826\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7604 - accuracy: 0.7143 - val_loss: 0.8425 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7595 - accuracy: 0.6813 - val_loss: 0.8458 - val_accuracy: 0.6522\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7619 - accuracy: 0.6154 - val_loss: 0.8499 - val_accuracy: 0.6522\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7611 - accuracy: 0.6154 - val_loss: 0.8461 - val_accuracy: 0.6522\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7574 - accuracy: 0.6264 - val_loss: 0.8396 - val_accuracy: 0.6957\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7559 - accuracy: 0.6703 - val_loss: 0.8395 - val_accuracy: 0.6957\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7446 - accuracy: 0.6593 - val_loss: 0.8407 - val_accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7514 - accuracy: 0.7033 - val_loss: 0.8418 - val_accuracy: 0.6957\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7426 - accuracy: 0.6264 - val_loss: 0.8493 - val_accuracy: 0.6957\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7420 - accuracy: 0.6264 - val_loss: 0.8513 - val_accuracy: 0.6957\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7434 - accuracy: 0.6484 - val_loss: 0.8452 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7372 - accuracy: 0.6593 - val_loss: 0.8445 - val_accuracy: 0.7826\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7256 - accuracy: 0.7033 - val_loss: 0.8465 - val_accuracy: 0.6957\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7146 - accuracy: 0.7033 - val_loss: 0.8599 - val_accuracy: 0.6957\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7340 - accuracy: 0.6484 - val_loss: 0.8526 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7314 - accuracy: 0.6593 - val_loss: 0.8489 - val_accuracy: 0.7826\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7203 - accuracy: 0.6813 - val_loss: 0.8506 - val_accuracy: 0.7391\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7398 - accuracy: 0.6703 - val_loss: 0.8544 - val_accuracy: 0.6957\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7338 - accuracy: 0.6813 - val_loss: 0.8515 - val_accuracy: 0.6957\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7222 - accuracy: 0.6703 - val_loss: 0.8473 - val_accuracy: 0.7826\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7280 - accuracy: 0.7033 - val_loss: 0.8465 - val_accuracy: 0.7391\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7063 - accuracy: 0.6923 - val_loss: 0.8581 - val_accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7108 - accuracy: 0.6813 - val_loss: 0.8460 - val_accuracy: 0.7391\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7153 - accuracy: 0.6484 - val_loss: 0.8388 - val_accuracy: 0.7826\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7280 - accuracy: 0.6923 - val_loss: 0.8457 - val_accuracy: 0.7391\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7144 - accuracy: 0.6813 - val_loss: 0.8415 - val_accuracy: 0.7826\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7089 - accuracy: 0.7033 - val_loss: 0.8349 - val_accuracy: 0.7826\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7055 - accuracy: 0.6703 - val_loss: 0.8351 - val_accuracy: 0.7826\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7096 - accuracy: 0.6484 - val_loss: 0.8574 - val_accuracy: 0.6957\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7002 - accuracy: 0.6813 - val_loss: 0.8474 - val_accuracy: 0.7826\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7127 - accuracy: 0.6923 - val_loss: 0.8426 - val_accuracy: 0.7826\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7432 - accuracy: 0.6593 - val_loss: 0.8884 - val_accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7105 - accuracy: 0.6484 - val_loss: 0.8573 - val_accuracy: 0.7826\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7115 - accuracy: 0.6813 - val_loss: 0.8523 - val_accuracy: 0.7826\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7184 - accuracy: 0.6593 - val_loss: 0.8600 - val_accuracy: 0.7826\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7087 - accuracy: 0.7033 - val_loss: 0.9008 - val_accuracy: 0.6957\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6953 - accuracy: 0.6703 - val_loss: 0.8628 - val_accuracy: 0.7826\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6871 - accuracy: 0.6923 - val_loss: 0.8638 - val_accuracy: 0.7826\n",
      "<keras.callbacks.History object at 0x7fe518392670>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Thermal Preference Accuracy: 0.6754385964912281\n",
      "Thermal Preference Weighted F1 Score: 0.6332743623765296\n"
     ]
    }
   ],
   "source": [
    "# # Train and evaluate thermal preference model (source: ASHRAE, target: ASHRAE)\n",
    "# print(\"Training Thermal Preference Model\")\n",
    "# thermalpref_model = define_model_architecture(num_classes=3)\n",
    "# thermalpref_model, thermalpref_scaler = train_model(thermalpref_model, \n",
    "#                                                     thermalpref_train, \n",
    "#                                                     model_name='cnnlstm_base_thermalpref_model', \n",
    "#                                                     target_col='Thermal Preference', \n",
    "#                                                     num_classes=3)\n",
    "\n",
    "# thermalpref_eval = evaluate_model(thermalpref_model, \n",
    "#                                   thermalpref_test, \n",
    "#                                   thermalpref_scaler,\n",
    "#                                   model_name='cnnlstm_base_thermalpref_model', \n",
    "#                                   target_col='Thermal Preference')\n",
    "# print(\"Thermal Preference Accuracy:\", thermalpref_eval['accuracy'])\n",
    "# print(\"Thermal Preference Weighted F1 Score:\", thermalpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Preference Model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 4, 128)            768       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 4, 256)            394240    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "554/554 [==============================] - 15s 23ms/step - loss: 0.9581 - accuracy: 0.5118 - val_loss: 0.9406 - val_accuracy: 0.5220\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 13s 23ms/step - loss: 0.9444 - accuracy: 0.5269 - val_loss: 0.9398 - val_accuracy: 0.5278\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 13s 23ms/step - loss: 0.9420 - accuracy: 0.5285 - val_loss: 0.9490 - val_accuracy: 0.5259\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 13s 23ms/step - loss: 0.9394 - accuracy: 0.5293 - val_loss: 0.9360 - val_accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 13s 24ms/step - loss: 0.9375 - accuracy: 0.5300 - val_loss: 0.9330 - val_accuracy: 0.5341\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 13s 23ms/step - loss: 0.9358 - accuracy: 0.5313 - val_loss: 0.9319 - val_accuracy: 0.5376\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 13s 23ms/step - loss: 0.9358 - accuracy: 0.5329 - val_loss: 0.9411 - val_accuracy: 0.5242\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9344 - accuracy: 0.5344 - val_loss: 0.9331 - val_accuracy: 0.5342\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 14s 24ms/step - loss: 0.9338 - accuracy: 0.5332 - val_loss: 0.9326 - val_accuracy: 0.5337\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9340 - accuracy: 0.5327 - val_loss: 0.9309 - val_accuracy: 0.5350\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9327 - accuracy: 0.5344 - val_loss: 0.9423 - val_accuracy: 0.5248\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9321 - accuracy: 0.5347 - val_loss: 0.9316 - val_accuracy: 0.5326\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9315 - accuracy: 0.5337 - val_loss: 0.9268 - val_accuracy: 0.5375\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9307 - accuracy: 0.5351 - val_loss: 0.9298 - val_accuracy: 0.5315\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9308 - accuracy: 0.5346 - val_loss: 0.9294 - val_accuracy: 0.5365\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9294 - accuracy: 0.5370 - val_loss: 0.9344 - val_accuracy: 0.5369\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9300 - accuracy: 0.5352 - val_loss: 0.9277 - val_accuracy: 0.5316\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 16s 28ms/step - loss: 0.9289 - accuracy: 0.5357 - val_loss: 0.9257 - val_accuracy: 0.5397\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9284 - accuracy: 0.5357 - val_loss: 0.9278 - val_accuracy: 0.5363\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 16s 28ms/step - loss: 0.9282 - accuracy: 0.5364 - val_loss: 0.9283 - val_accuracy: 0.5323\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9264 - accuracy: 0.5375 - val_loss: 0.9290 - val_accuracy: 0.5325\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9270 - accuracy: 0.5370 - val_loss: 0.9255 - val_accuracy: 0.5402\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9255 - accuracy: 0.5382 - val_loss: 0.9262 - val_accuracy: 0.5328\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9258 - accuracy: 0.5371 - val_loss: 0.9223 - val_accuracy: 0.5406\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9250 - accuracy: 0.5378 - val_loss: 0.9322 - val_accuracy: 0.5251\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9248 - accuracy: 0.5394 - val_loss: 0.9270 - val_accuracy: 0.5351\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9237 - accuracy: 0.5393 - val_loss: 0.9244 - val_accuracy: 0.5381\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9234 - accuracy: 0.5397 - val_loss: 0.9205 - val_accuracy: 0.5407\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9224 - accuracy: 0.5402 - val_loss: 0.9212 - val_accuracy: 0.5432\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9234 - accuracy: 0.5392 - val_loss: 0.9266 - val_accuracy: 0.5327\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9227 - accuracy: 0.5389 - val_loss: 0.9210 - val_accuracy: 0.5431\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 18s 32ms/step - loss: 0.9216 - accuracy: 0.5409 - val_loss: 0.9200 - val_accuracy: 0.5446\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9210 - accuracy: 0.5425 - val_loss: 0.9224 - val_accuracy: 0.5404\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9214 - accuracy: 0.5416 - val_loss: 0.9190 - val_accuracy: 0.5424\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9201 - accuracy: 0.5420 - val_loss: 0.9206 - val_accuracy: 0.5396\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9199 - accuracy: 0.5426 - val_loss: 0.9193 - val_accuracy: 0.5416\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9201 - accuracy: 0.5417 - val_loss: 0.9175 - val_accuracy: 0.5402\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9186 - accuracy: 0.5440 - val_loss: 0.9194 - val_accuracy: 0.5433\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9185 - accuracy: 0.5420 - val_loss: 0.9222 - val_accuracy: 0.5380\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9184 - accuracy: 0.5431 - val_loss: 0.9172 - val_accuracy: 0.5413\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9180 - accuracy: 0.5442 - val_loss: 0.9223 - val_accuracy: 0.5396\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9177 - accuracy: 0.5433 - val_loss: 0.9171 - val_accuracy: 0.5416\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 15s 27ms/step - loss: 0.9161 - accuracy: 0.5437 - val_loss: 0.9145 - val_accuracy: 0.5424\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 15s 26ms/step - loss: 0.9168 - accuracy: 0.5450 - val_loss: 0.9193 - val_accuracy: 0.5407\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 16s 28ms/step - loss: 0.9176 - accuracy: 0.5434 - val_loss: 0.9160 - val_accuracy: 0.5441\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 16s 28ms/step - loss: 0.9154 - accuracy: 0.5449 - val_loss: 0.9166 - val_accuracy: 0.5415\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 16s 29ms/step - loss: 0.9139 - accuracy: 0.5464 - val_loss: 0.9133 - val_accuracy: 0.5439\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - 15s 28ms/step - loss: 0.9141 - accuracy: 0.5449 - val_loss: 0.9135 - val_accuracy: 0.5460\n",
      "Epoch 49/100\n",
      "272/554 [=============>................] - ETA: 7s - loss: 0.9125 - accuracy: 0.5477"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal preference model (source: ASHRAE, target: ASHRAE)\n",
    "print(\"Training Thermal Preference Model\")\n",
    "\n",
    "# Define the model architecture\n",
    "thermalpref_model = define_model_architecture(num_classes=3)\n",
    "\n",
    "# Train the model using the training and evaluation datasets\n",
    "thermalpref_model, thermalpref_scaler = train_model(thermalpref_model, \n",
    "                                                    train_df=thermalpref_train, \n",
    "                                                    eval_df=thermalpref_eval, \n",
    "                                                    model_name='cnnlstm_base_thermalpref_model', \n",
    "                                                    target_col='Thermal Preference', \n",
    "                                                    num_classes=3)\n",
    "\n",
    "# Evaluate the model using the test dataset\n",
    "thermalpref_eval_results = evaluate_model(thermalpref_model, \n",
    "                                          test_df=thermalpref_test, \n",
    "                                          scaler=thermalpref_scaler,\n",
    "                                          model_name='cnnlstm_base_thermalpref_model', \n",
    "                                          target_col='Thermal Preference')\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Thermal Preference Accuracy:\", thermalpref_eval_results['accuracy'])\n",
    "print(\"Thermal Preference Weighted F1 Score:\", thermalpref_eval_results['weighted_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Acceptability Model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,842\n",
      "Trainable params: 937,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6992 - accuracy: 0.1978 - val_loss: 0.6867 - val_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6828 - accuracy: 0.8022 - val_loss: 0.6783 - val_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6687 - accuracy: 0.8022 - val_loss: 0.6678 - val_accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6491 - accuracy: 0.8022 - val_loss: 0.6563 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6224 - accuracy: 0.8022 - val_loss: 0.6489 - val_accuracy: 0.6957\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5886 - accuracy: 0.8022 - val_loss: 0.6642 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5553 - accuracy: 0.8022 - val_loss: 0.7391 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5459 - accuracy: 0.8022 - val_loss: 0.8247 - val_accuracy: 0.6957\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5668 - accuracy: 0.8022 - val_loss: 0.8156 - val_accuracy: 0.6957\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5595 - accuracy: 0.8022 - val_loss: 0.7581 - val_accuracy: 0.6957\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5402 - accuracy: 0.8022 - val_loss: 0.7016 - val_accuracy: 0.6957\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5310 - accuracy: 0.8022 - val_loss: 0.6634 - val_accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5272 - accuracy: 0.8022 - val_loss: 0.6446 - val_accuracy: 0.6957\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5309 - accuracy: 0.8022 - val_loss: 0.6363 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5312 - accuracy: 0.8022 - val_loss: 0.6355 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5258 - accuracy: 0.8022 - val_loss: 0.6384 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5203 - accuracy: 0.8022 - val_loss: 0.6461 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5136 - accuracy: 0.8022 - val_loss: 0.6592 - val_accuracy: 0.6957\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5103 - accuracy: 0.8022 - val_loss: 0.6753 - val_accuracy: 0.6957\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5080 - accuracy: 0.8022 - val_loss: 0.6874 - val_accuracy: 0.6957\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5087 - accuracy: 0.8022 - val_loss: 0.6891 - val_accuracy: 0.6957\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5085 - accuracy: 0.8022 - val_loss: 0.6795 - val_accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5061 - accuracy: 0.8022 - val_loss: 0.6621 - val_accuracy: 0.6957\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5006 - accuracy: 0.8022 - val_loss: 0.6418 - val_accuracy: 0.6957\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4973 - accuracy: 0.8022 - val_loss: 0.6234 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4947 - accuracy: 0.8022 - val_loss: 0.6094 - val_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4945 - accuracy: 0.8022 - val_loss: 0.5997 - val_accuracy: 0.6957\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4928 - accuracy: 0.8022 - val_loss: 0.5934 - val_accuracy: 0.6957\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4916 - accuracy: 0.8022 - val_loss: 0.5904 - val_accuracy: 0.6957\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4852 - accuracy: 0.8022 - val_loss: 0.5900 - val_accuracy: 0.6957\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4821 - accuracy: 0.8022 - val_loss: 0.5899 - val_accuracy: 0.6957\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4774 - accuracy: 0.8022 - val_loss: 0.5823 - val_accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4778 - accuracy: 0.8022 - val_loss: 0.5613 - val_accuracy: 0.6957\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4673 - accuracy: 0.8022 - val_loss: 0.5287 - val_accuracy: 0.6957\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4697 - accuracy: 0.8022 - val_loss: 0.5051 - val_accuracy: 0.6957\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4748 - accuracy: 0.8022 - val_loss: 0.5204 - val_accuracy: 0.6957\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4669 - accuracy: 0.8022 - val_loss: 0.5435 - val_accuracy: 0.6957\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4763 - accuracy: 0.8022 - val_loss: 0.5248 - val_accuracy: 0.6957\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4763 - accuracy: 0.8022 - val_loss: 0.4960 - val_accuracy: 0.6957\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4645 - accuracy: 0.8022 - val_loss: 0.4803 - val_accuracy: 0.6957\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4770 - accuracy: 0.7912 - val_loss: 0.5018 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4670 - accuracy: 0.8022 - val_loss: 0.5158 - val_accuracy: 0.6957\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4639 - accuracy: 0.8022 - val_loss: 0.5197 - val_accuracy: 0.6957\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4658 - accuracy: 0.8022 - val_loss: 0.5154 - val_accuracy: 0.6957\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4591 - accuracy: 0.8022 - val_loss: 0.4895 - val_accuracy: 0.6957\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4634 - accuracy: 0.8022 - val_loss: 0.4935 - val_accuracy: 0.6957\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4555 - accuracy: 0.8132 - val_loss: 0.5336 - val_accuracy: 0.6957\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4553 - accuracy: 0.8022 - val_loss: 0.5227 - val_accuracy: 0.6957\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4585 - accuracy: 0.8022 - val_loss: 0.4783 - val_accuracy: 0.6957\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4591 - accuracy: 0.7912 - val_loss: 0.4954 - val_accuracy: 0.6957\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4526 - accuracy: 0.8132 - val_loss: 0.5206 - val_accuracy: 0.6957\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4486 - accuracy: 0.8022 - val_loss: 0.4559 - val_accuracy: 0.6957\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4571 - accuracy: 0.8132 - val_loss: 0.4789 - val_accuracy: 0.6957\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4415 - accuracy: 0.8352 - val_loss: 0.4570 - val_accuracy: 0.6522\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4366 - accuracy: 0.8022 - val_loss: 0.4531 - val_accuracy: 0.6957\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4345 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.6957\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4637 - accuracy: 0.8022 - val_loss: 0.4291 - val_accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4198 - accuracy: 0.8242 - val_loss: 0.4247 - val_accuracy: 0.8261\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4206 - accuracy: 0.8462 - val_loss: 0.6175 - val_accuracy: 0.6957\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4632 - accuracy: 0.8022 - val_loss: 0.4282 - val_accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4252 - accuracy: 0.8132 - val_loss: 0.4046 - val_accuracy: 0.8696\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4259 - accuracy: 0.8132 - val_loss: 0.6337 - val_accuracy: 0.6957\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4504 - accuracy: 0.8132 - val_loss: 0.5777 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4622 - accuracy: 0.8022 - val_loss: 0.4540 - val_accuracy: 0.7826\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4700 - accuracy: 0.7582 - val_loss: 0.4521 - val_accuracy: 0.6957\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4143 - accuracy: 0.8022 - val_loss: 0.5402 - val_accuracy: 0.6522\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4443 - accuracy: 0.8132 - val_loss: 0.5073 - val_accuracy: 0.6522\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4278 - accuracy: 0.8022 - val_loss: 0.4289 - val_accuracy: 0.7391\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4387 - accuracy: 0.8242 - val_loss: 0.4109 - val_accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4211 - accuracy: 0.8242 - val_loss: 0.4377 - val_accuracy: 0.6957\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4161 - accuracy: 0.8462 - val_loss: 0.4958 - val_accuracy: 0.6522\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4487 - accuracy: 0.7802 - val_loss: 0.4853 - val_accuracy: 0.6522\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4141 - accuracy: 0.8352 - val_loss: 0.4303 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4301 - accuracy: 0.8132 - val_loss: 0.4105 - val_accuracy: 0.8696\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4205 - accuracy: 0.8022 - val_loss: 0.4072 - val_accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4315 - accuracy: 0.8022 - val_loss: 0.4566 - val_accuracy: 0.6522\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4073 - accuracy: 0.8132 - val_loss: 0.5307 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4501 - accuracy: 0.7912 - val_loss: 0.4750 - val_accuracy: 0.6522\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4130 - accuracy: 0.8462 - val_loss: 0.4187 - val_accuracy: 0.7826\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4247 - accuracy: 0.8022 - val_loss: 0.4063 - val_accuracy: 0.8696\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4361 - accuracy: 0.7912 - val_loss: 0.4036 - val_accuracy: 0.8696\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4218 - accuracy: 0.8132 - val_loss: 0.4722 - val_accuracy: 0.6522\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4134 - accuracy: 0.8132 - val_loss: 0.4727 - val_accuracy: 0.6522\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4050 - accuracy: 0.8242 - val_loss: 0.4095 - val_accuracy: 0.8696\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4190 - accuracy: 0.8022 - val_loss: 0.4129 - val_accuracy: 0.8696\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3943 - accuracy: 0.8462 - val_loss: 0.4037 - val_accuracy: 0.8696\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4092 - accuracy: 0.8132 - val_loss: 0.4369 - val_accuracy: 0.7826\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4072 - accuracy: 0.8132 - val_loss: 0.4460 - val_accuracy: 0.7391\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4165 - accuracy: 0.8462 - val_loss: 0.4010 - val_accuracy: 0.8696\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4172 - accuracy: 0.8022 - val_loss: 0.3982 - val_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4122 - accuracy: 0.8242 - val_loss: 0.4083 - val_accuracy: 0.8696\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4193 - accuracy: 0.8022 - val_loss: 0.4187 - val_accuracy: 0.8696\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4151 - accuracy: 0.8132 - val_loss: 0.4004 - val_accuracy: 0.8261\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - accuracy: 0.8242 - val_loss: 0.4124 - val_accuracy: 0.8696\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4149 - accuracy: 0.8022 - val_loss: 0.4157 - val_accuracy: 0.8696\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4258 - accuracy: 0.7912 - val_loss: 0.3992 - val_accuracy: 0.8696\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4167 - accuracy: 0.8242 - val_loss: 0.3975 - val_accuracy: 0.8696\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4155 - accuracy: 0.8132 - val_loss: 0.4195 - val_accuracy: 0.8696\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3980 - accuracy: 0.8022 - val_loss: 0.4525 - val_accuracy: 0.7391\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3962 - accuracy: 0.8132 - val_loss: 0.4594 - val_accuracy: 0.7391\n",
      "<keras.callbacks.History object at 0x7fe508d88f70>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Thermal Acceptability Accuracy: 0.8228070175438597\n",
      "Thermal Acceptability Weighted F1 Score: 0.8002772174474023\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal acceptability model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Acceptability Model\")\n",
    "thermalacc_model = define_model_architecture(num_classes=2)\n",
    "thermalacc_model, thermalacc_scaler = train_model(thermalacc_model, \n",
    "                                                  thermalacc_train, \n",
    "                                                  model_name='cnnlstm_base_thermalacc_model', \n",
    "                                                  target_col='Thermal Acceptability', \n",
    "                                                  num_classes=2)\n",
    "\n",
    "thermalacc_eval = evaluate_model(thermalacc_model, \n",
    "                                 thermalacc_test, \n",
    "                                 thermalacc_scaler,\n",
    "                                 model_name='cnnlstm_base_thermalacc_model', \n",
    "                                 target_col='Thermal Acceptability')\n",
    "print(\"Thermal Acceptability Accuracy:\", thermalacc_eval['accuracy'])\n",
    "print(\"Thermal Acceptability Weighted F1 Score:\", thermalacc_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Air Movement Preference Model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0975 - accuracy: 0.4945 - val_loss: 1.0847 - val_accuracy: 0.3913\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0738 - accuracy: 0.4945 - val_loss: 1.0669 - val_accuracy: 0.3913\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.0374 - accuracy: 0.4945 - val_loss: 1.0593 - val_accuracy: 0.3913\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0003 - accuracy: 0.4945 - val_loss: 1.0834 - val_accuracy: 0.3913\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9767 - accuracy: 0.4945 - val_loss: 1.1550 - val_accuracy: 0.3913\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9838 - accuracy: 0.4945 - val_loss: 1.1627 - val_accuracy: 0.3913\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9868 - accuracy: 0.4945 - val_loss: 1.1229 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9735 - accuracy: 0.4945 - val_loss: 1.0786 - val_accuracy: 0.3913\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9647 - accuracy: 0.4945 - val_loss: 1.0487 - val_accuracy: 0.3913\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9647 - accuracy: 0.4945 - val_loss: 1.0340 - val_accuracy: 0.3913\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9664 - accuracy: 0.4945 - val_loss: 1.0280 - val_accuracy: 0.3913\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9680 - accuracy: 0.4945 - val_loss: 1.0259 - val_accuracy: 0.3913\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9645 - accuracy: 0.4945 - val_loss: 1.0277 - val_accuracy: 0.3913\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9583 - accuracy: 0.4945 - val_loss: 1.0338 - val_accuracy: 0.3913\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9547 - accuracy: 0.4945 - val_loss: 1.0434 - val_accuracy: 0.3913\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9518 - accuracy: 0.4945 - val_loss: 1.0531 - val_accuracy: 0.3913\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9534 - accuracy: 0.4945 - val_loss: 1.0563 - val_accuracy: 0.3913\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9531 - accuracy: 0.4945 - val_loss: 1.0499 - val_accuracy: 0.3913\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9499 - accuracy: 0.4945 - val_loss: 1.0371 - val_accuracy: 0.3913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9475 - accuracy: 0.4945 - val_loss: 1.0228 - val_accuracy: 0.3913\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9458 - accuracy: 0.4945 - val_loss: 1.0107 - val_accuracy: 0.3913\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9461 - accuracy: 0.4945 - val_loss: 1.0028 - val_accuracy: 0.3913\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9449 - accuracy: 0.4945 - val_loss: 0.9986 - val_accuracy: 0.3913\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9440 - accuracy: 0.4945 - val_loss: 0.9970 - val_accuracy: 0.3913\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9418 - accuracy: 0.4945 - val_loss: 0.9983 - val_accuracy: 0.3913\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9392 - accuracy: 0.4945 - val_loss: 1.0006 - val_accuracy: 0.3913\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9393 - accuracy: 0.4945 - val_loss: 0.9980 - val_accuracy: 0.3913\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9383 - accuracy: 0.4945 - val_loss: 0.9872 - val_accuracy: 0.3913\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9357 - accuracy: 0.4945 - val_loss: 0.9705 - val_accuracy: 0.3913\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9349 - accuracy: 0.4945 - val_loss: 0.9565 - val_accuracy: 0.3913\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9351 - accuracy: 0.4945 - val_loss: 0.9501 - val_accuracy: 0.3913\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9365 - accuracy: 0.4945 - val_loss: 0.9528 - val_accuracy: 0.3913\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9342 - accuracy: 0.4945 - val_loss: 0.9613 - val_accuracy: 0.3913\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9343 - accuracy: 0.4945 - val_loss: 0.9592 - val_accuracy: 0.3913\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9369 - accuracy: 0.4945 - val_loss: 0.9440 - val_accuracy: 0.4783\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9336 - accuracy: 0.5275 - val_loss: 0.9391 - val_accuracy: 0.4783\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9330 - accuracy: 0.5495 - val_loss: 0.9476 - val_accuracy: 0.4348\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9327 - accuracy: 0.4615 - val_loss: 0.9542 - val_accuracy: 0.3913\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9315 - accuracy: 0.4835 - val_loss: 0.9510 - val_accuracy: 0.3913\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9341 - accuracy: 0.4945 - val_loss: 0.9450 - val_accuracy: 0.4348\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9342 - accuracy: 0.5165 - val_loss: 0.9423 - val_accuracy: 0.4783\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9311 - accuracy: 0.5385 - val_loss: 0.9441 - val_accuracy: 0.5217\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9324 - accuracy: 0.5165 - val_loss: 0.9500 - val_accuracy: 0.5217\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9306 - accuracy: 0.5275 - val_loss: 0.9575 - val_accuracy: 0.4783\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9292 - accuracy: 0.5165 - val_loss: 0.9654 - val_accuracy: 0.3913\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9296 - accuracy: 0.4945 - val_loss: 0.9632 - val_accuracy: 0.4348\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9286 - accuracy: 0.4945 - val_loss: 0.9571 - val_accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9275 - accuracy: 0.5275 - val_loss: 0.9557 - val_accuracy: 0.5217\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9301 - accuracy: 0.5165 - val_loss: 0.9574 - val_accuracy: 0.4783\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9285 - accuracy: 0.4835 - val_loss: 0.9588 - val_accuracy: 0.4783\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9247 - accuracy: 0.5495 - val_loss: 0.9595 - val_accuracy: 0.4348\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9268 - accuracy: 0.5714 - val_loss: 0.9560 - val_accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9274 - accuracy: 0.5604 - val_loss: 0.9521 - val_accuracy: 0.5217\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9275 - accuracy: 0.5275 - val_loss: 0.9498 - val_accuracy: 0.5217\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9283 - accuracy: 0.5165 - val_loss: 0.9480 - val_accuracy: 0.5217\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9261 - accuracy: 0.5055 - val_loss: 0.9495 - val_accuracy: 0.4783\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9273 - accuracy: 0.5165 - val_loss: 0.9484 - val_accuracy: 0.4348\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9259 - accuracy: 0.4945 - val_loss: 0.9430 - val_accuracy: 0.5217\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9273 - accuracy: 0.4945 - val_loss: 0.9380 - val_accuracy: 0.5217\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9205 - accuracy: 0.4945 - val_loss: 0.9428 - val_accuracy: 0.5217\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9216 - accuracy: 0.5275 - val_loss: 0.9503 - val_accuracy: 0.4348\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9211 - accuracy: 0.5055 - val_loss: 0.9485 - val_accuracy: 0.5217\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9253 - accuracy: 0.5275 - val_loss: 0.9441 - val_accuracy: 0.5217\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9168 - accuracy: 0.5275 - val_loss: 0.9445 - val_accuracy: 0.5217\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9183 - accuracy: 0.5055 - val_loss: 0.9482 - val_accuracy: 0.5217\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9154 - accuracy: 0.5275 - val_loss: 0.9490 - val_accuracy: 0.5217\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9139 - accuracy: 0.5495 - val_loss: 0.9455 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9146 - accuracy: 0.5165 - val_loss: 0.9419 - val_accuracy: 0.5217\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9121 - accuracy: 0.5055 - val_loss: 0.9427 - val_accuracy: 0.5217\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9117 - accuracy: 0.5165 - val_loss: 0.9469 - val_accuracy: 0.5217\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9118 - accuracy: 0.5055 - val_loss: 0.9403 - val_accuracy: 0.5217\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9078 - accuracy: 0.5385 - val_loss: 0.9408 - val_accuracy: 0.4783\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8964 - accuracy: 0.5275 - val_loss: 0.9448 - val_accuracy: 0.5217\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8993 - accuracy: 0.5165 - val_loss: 0.9358 - val_accuracy: 0.5217\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8908 - accuracy: 0.5275 - val_loss: 0.9325 - val_accuracy: 0.4783\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8918 - accuracy: 0.5714 - val_loss: 0.9350 - val_accuracy: 0.5217\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8895 - accuracy: 0.5604 - val_loss: 0.9380 - val_accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8727 - accuracy: 0.5275 - val_loss: 1.0033 - val_accuracy: 0.3478\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9270 - accuracy: 0.4945 - val_loss: 1.0039 - val_accuracy: 0.5217\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8898 - accuracy: 0.5275 - val_loss: 0.9689 - val_accuracy: 0.4783\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8738 - accuracy: 0.5165 - val_loss: 0.9313 - val_accuracy: 0.4348\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8723 - accuracy: 0.5824 - val_loss: 0.9545 - val_accuracy: 0.3043\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8781 - accuracy: 0.5055 - val_loss: 0.9812 - val_accuracy: 0.3913\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8743 - accuracy: 0.5714 - val_loss: 0.9851 - val_accuracy: 0.4783\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8738 - accuracy: 0.5714 - val_loss: 0.9549 - val_accuracy: 0.4783\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8694 - accuracy: 0.5495 - val_loss: 0.9562 - val_accuracy: 0.4783\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8642 - accuracy: 0.5495 - val_loss: 0.9639 - val_accuracy: 0.4348\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8664 - accuracy: 0.5385 - val_loss: 1.0058 - val_accuracy: 0.4348\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8528 - accuracy: 0.5824 - val_loss: 0.9881 - val_accuracy: 0.3913\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8627 - accuracy: 0.5275 - val_loss: 0.9603 - val_accuracy: 0.3913\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8556 - accuracy: 0.5714 - val_loss: 1.0040 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8541 - accuracy: 0.5385 - val_loss: 0.9902 - val_accuracy: 0.4783\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8444 - accuracy: 0.5495 - val_loss: 0.9533 - val_accuracy: 0.2609\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8633 - accuracy: 0.4945 - val_loss: 1.0377 - val_accuracy: 0.5217\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8561 - accuracy: 0.5714 - val_loss: 0.9649 - val_accuracy: 0.4783\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8261 - accuracy: 0.5604 - val_loss: 0.9310 - val_accuracy: 0.3478\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8435 - accuracy: 0.5604 - val_loss: 0.9622 - val_accuracy: 0.4783\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8278 - accuracy: 0.5824 - val_loss: 1.0092 - val_accuracy: 0.4783\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8278 - accuracy: 0.5934 - val_loss: 0.9306 - val_accuracy: 0.3913\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8280 - accuracy: 0.5714 - val_loss: 0.9601 - val_accuracy: 0.4348\n",
      "<keras.callbacks.History object at 0x7fe4fe173880>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Air Movement Preference Accuracy: 0.5736842105263158\n",
      "Air Movement Preference Weighted F1 Score: 0.5372460316522274\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate air movement preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Air Movement Preference Model\")\n",
    "airpref_model = define_model_architecture(num_classes=3)\n",
    "airpref_model, airpref_scaler = train_model(airpref_model, \n",
    "                                            airpref_train, \n",
    "                                            model_name='cnnlstm_base_airpref_model', \n",
    "                                            target_col='Air Movement Preference', \n",
    "                                            num_classes=3)\n",
    "\n",
    "airpref_eval = evaluate_model(airpref_model, \n",
    "                              airpref_test, \n",
    "                              airpref_scaler,\n",
    "                              model_name='cnnlstm_base_airpref_model', \n",
    "                              target_col='Air Movement Preference')\n",
    "print(\"Air Movement Preference Accuracy:\", airpref_eval['accuracy'])\n",
    "print(\"Air Movement Preference Weighted F1 Score:\", airpref_eval['weighted_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
