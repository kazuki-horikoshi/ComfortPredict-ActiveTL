{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries and model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 13:03:47.943627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 13:03:48.186303: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-11 13:03:48.232921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-11 13:03:48.232935: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-11 13:03:48.958735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-11 13:03:48.958822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-11 13:03:48.958826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "random.seed(1)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Define model hyperparameters\n",
    "parser = argparse.ArgumentParser(description='CNN-LSTM Base Model')\n",
    "parser.add_argument('--input_size', type=int, default=7)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "parser.add_argument('--input_features', type=list, default=['Mode',\n",
    "                                                            'Indoor Temp',\n",
    "                                                            'Indoor Humidity',\n",
    "                                                            'Air Velocity',\n",
    "                                                            'Globe Temperature',\n",
    "                                                            'Outdoor Temp',\n",
    "                                                            'Outdoor Humidity'])\n",
    "parser.add_argument('--experiment', type=str, default='mode_random') \n",
    "# choose either 'condition_random', 'mode_random', 'mode_al'\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "mode_mapping = {'AC':0, 'NV':1}\n",
    "thermalpref_mapping = {'No Change':0, 'Warmer':1, 'Cooler':2}\n",
    "thermalacc_mapping = {'Acceptable':0, 'Unacceptable':1}\n",
    "airpref_mapping = {'No Change':0, 'More':1, 'Less':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load training data from BCA dataset\n",
    "if args.experiment == 'condition_random':\n",
    "    thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_condition_random_data.csv')\n",
    "    thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_condition_random_data.csv')\n",
    "    airpref_train = pd.read_csv('../data/bca_airpref_train_condition_random_data.csv')\n",
    "elif args.experiment == 'mode_random':\n",
    "    thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_random_data.csv')\n",
    "    thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_random_data.csv')\n",
    "    airpref_train = pd.read_csv('../data/bca_airpref_train_mode_random_data.csv')\n",
    "elif args.experiment == 'mode_al':\n",
    "    thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_al_data.csv')\n",
    "    thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_al_data.csv')\n",
    "    airpref_train = pd.read_csv('../data/bca_airpref_train_mode_al_data.csv')\n",
    "else:\n",
    "    raise ValueError(f\"Experiment {args.experiment} is not supported.\")\n",
    "\n",
    "# load test data from BCA dataset\n",
    "thermalpref_test = pd.read_csv('../data/bca_thermalpref_test_data.csv')\n",
    "thermalacc_test = pd.read_csv('../data/bca_thermalacc_test_data.csv')\n",
    "airpref_test = pd.read_csv('../data/bca_airpref_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# perform one hot encoding\n",
    "thermalpref_train['Mode'] = thermalpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "thermalpref_test['Mode'] = thermalpref_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "thermalacc_train['Mode'] = thermalacc_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "thermalacc_test['Mode'] = thermalacc_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "airpref_train['Mode'] = airpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "airpref_test['Mode'] = airpref_test['Mode'].apply(lambda x: mode_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform label mapping\n",
    "thermalpref_train['Thermal Preference'] = thermalpref_train['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "thermalpref_test['Thermal Preference'] = thermalpref_test['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "\n",
    "thermalacc_train['Thermal Acceptability'] = thermalacc_train['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "thermalacc_test['Thermal Acceptability'] = thermalacc_test['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "\n",
    "airpref_train['Air Movement Preference'] = airpref_train['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "airpref_test['Air Movement Preference'] = airpref_test['Air Movement Preference'].apply(lambda x: airpref_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_model_architecture(num_classes):\n",
    "    \"\"\"\n",
    "    Defines the CNN LSTM model architecture with model parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        num_classes: An integer value indicating the number of output classes for the model.\n",
    "        \n",
    "    Return:\n",
    "        model: The Keras object containing the CNN LSTM model architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Convolutional Layer (Part of the model to be retrained)\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same', input_shape=(args.input_size, 1), trainable=True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Two LSTM Layers (Part of the model to be retrained)\n",
    "    model.add(LSTM(256, return_sequences=True, recurrent_dropout=0.1, trainable=True))\n",
    "    model.add(LSTM(256, return_sequences=False, recurrent_dropout=0.1, trainable=True))\n",
    "\n",
    "    # Flatten the output from LSTM layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Two Dense (Fully Connected) Layers (These layers will remain fixed)\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "\n",
    "    # Output Layer (Part of the model to be retrained)\n",
    "    model.add(Dense(num_classes, activation='softmax', trainable=True))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_df, model_name, target_col, num_classes):\n",
    "    # Assuming train_df has columns for features and a 'target' column for labels\n",
    "    X = np.array(train_df[args.input_features])\n",
    "    y = np.array(train_df[target_col])\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Create and fit a Min-Max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss\n",
    "        patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True  # Restore the best model weights when training stops\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_scaled, \n",
    "                        y_train, \n",
    "                        epochs=args.num_epochs, \n",
    "                        batch_size=args.batch_size,\n",
    "                        validation_data=(X_val_scaled, y_val), \n",
    "                        callbacks=[checkpoint_callback])\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "    print(history)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "def evaluate_model(model, test_df, scaler, model_name, target_col, metrics=['accuracy', 'weighted_f1']):\n",
    "    # Assuming test_df has columns for features and a 'target' column for labels\n",
    "    X_test = np.array(test_df[args.input_features])\n",
    "    y_true = np.array(test_df[target_col])\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    loaded_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "    \n",
    "    # Apply numerical scaler on X_test\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    y_pred = loaded_model.predict(X_test_scaled)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    if 'accuracy' in metrics:\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        evaluation_results['accuracy'] = accuracy\n",
    "\n",
    "    if 'weighted_f1' in metrics:\n",
    "        weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "        evaluation_results['weighted_f1'] = weighted_f1\n",
    "\n",
    "    return evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Preference Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 13:10:30.177282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-08-11 13:10:30.177728: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-11 13:10:30.177752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7bde9dfab31b): /proc/driver/nvidia/version does not exist\n",
      "2024-08-11 13:10:30.178731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1032 - accuracy: 0.0659 - val_loss: 1.0897 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.0887 - accuracy: 0.5055 - val_loss: 1.0765 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0739 - accuracy: 0.5055 - val_loss: 1.0542 - val_accuracy: 0.5652\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.0499 - accuracy: 0.5055 - val_loss: 1.0275 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0211 - accuracy: 0.5055 - val_loss: 0.9957 - val_accuracy: 0.5652\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9839 - accuracy: 0.5055 - val_loss: 0.9669 - val_accuracy: 0.5652\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9425 - accuracy: 0.5055 - val_loss: 0.9492 - val_accuracy: 0.5652\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9029 - accuracy: 0.5055 - val_loss: 0.9406 - val_accuracy: 0.5652\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8600 - accuracy: 0.5055 - val_loss: 0.9709 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8447 - accuracy: 0.4835 - val_loss: 1.0437 - val_accuracy: 0.3478\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8792 - accuracy: 0.4396 - val_loss: 1.0316 - val_accuracy: 0.3478\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8695 - accuracy: 0.4835 - val_loss: 1.0129 - val_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8704 - accuracy: 0.5055 - val_loss: 1.0011 - val_accuracy: 0.5652\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8695 - accuracy: 0.5055 - val_loss: 0.9817 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8505 - accuracy: 0.6264 - val_loss: 0.9701 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8443 - accuracy: 0.5714 - val_loss: 0.9518 - val_accuracy: 0.6087\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8387 - accuracy: 0.5604 - val_loss: 0.9264 - val_accuracy: 0.6522\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8351 - accuracy: 0.6154 - val_loss: 0.9086 - val_accuracy: 0.6522\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8318 - accuracy: 0.6374 - val_loss: 0.8998 - val_accuracy: 0.6522\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8366 - accuracy: 0.5165 - val_loss: 0.8942 - val_accuracy: 0.6087\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8353 - accuracy: 0.6044 - val_loss: 0.8911 - val_accuracy: 0.6522\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8302 - accuracy: 0.6374 - val_loss: 0.8941 - val_accuracy: 0.6522\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8267 - accuracy: 0.6044 - val_loss: 0.8956 - val_accuracy: 0.6522\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8211 - accuracy: 0.6044 - val_loss: 0.8886 - val_accuracy: 0.6522\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8143 - accuracy: 0.6044 - val_loss: 0.8747 - val_accuracy: 0.6522\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8124 - accuracy: 0.6264 - val_loss: 0.8681 - val_accuracy: 0.6522\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8143 - accuracy: 0.6264 - val_loss: 0.8671 - val_accuracy: 0.6522\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8117 - accuracy: 0.6484 - val_loss: 0.8729 - val_accuracy: 0.6522\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8060 - accuracy: 0.6264 - val_loss: 0.8736 - val_accuracy: 0.6522\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8123 - accuracy: 0.6044 - val_loss: 0.8591 - val_accuracy: 0.6522\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8053 - accuracy: 0.6264 - val_loss: 0.8506 - val_accuracy: 0.6522\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8066 - accuracy: 0.6484 - val_loss: 0.8482 - val_accuracy: 0.6522\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7975 - accuracy: 0.6264 - val_loss: 0.8502 - val_accuracy: 0.6522\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7955 - accuracy: 0.6484 - val_loss: 0.8409 - val_accuracy: 0.6522\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7921 - accuracy: 0.6374 - val_loss: 0.8386 - val_accuracy: 0.6522\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7947 - accuracy: 0.6374 - val_loss: 0.8412 - val_accuracy: 0.6522\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7826 - accuracy: 0.6484 - val_loss: 0.8453 - val_accuracy: 0.6522\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7864 - accuracy: 0.6154 - val_loss: 0.8344 - val_accuracy: 0.6522\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7784 - accuracy: 0.6484 - val_loss: 0.8332 - val_accuracy: 0.6522\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7806 - accuracy: 0.6264 - val_loss: 0.8357 - val_accuracy: 0.6522\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7740 - accuracy: 0.6484 - val_loss: 0.8293 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7686 - accuracy: 0.6374 - val_loss: 0.8373 - val_accuracy: 0.6522\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7839 - accuracy: 0.6154 - val_loss: 0.8559 - val_accuracy: 0.6522\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8064 - accuracy: 0.6044 - val_loss: 0.9584 - val_accuracy: 0.6522\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8573 - accuracy: 0.6044 - val_loss: 0.8773 - val_accuracy: 0.6522\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7937 - accuracy: 0.6044 - val_loss: 0.8972 - val_accuracy: 0.5652\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8375 - accuracy: 0.5385 - val_loss: 0.8777 - val_accuracy: 0.5652\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8176 - accuracy: 0.5714 - val_loss: 0.8582 - val_accuracy: 0.6522\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7736 - accuracy: 0.6044 - val_loss: 0.9225 - val_accuracy: 0.6522\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8287 - accuracy: 0.6044 - val_loss: 0.9027 - val_accuracy: 0.6522\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8032 - accuracy: 0.6044 - val_loss: 0.8607 - val_accuracy: 0.6522\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7708 - accuracy: 0.6044 - val_loss: 0.8590 - val_accuracy: 0.7826\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7852 - accuracy: 0.6593 - val_loss: 0.8672 - val_accuracy: 0.6087\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7884 - accuracy: 0.6154 - val_loss: 0.8554 - val_accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7831 - accuracy: 0.6703 - val_loss: 0.8508 - val_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7711 - accuracy: 0.6264 - val_loss: 0.8634 - val_accuracy: 0.6522\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7751 - accuracy: 0.6044 - val_loss: 0.8759 - val_accuracy: 0.6522\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7835 - accuracy: 0.6044 - val_loss: 0.8697 - val_accuracy: 0.6522\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7884 - accuracy: 0.6044 - val_loss: 0.8542 - val_accuracy: 0.6522\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7762 - accuracy: 0.6264 - val_loss: 0.8457 - val_accuracy: 0.6957\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7635 - accuracy: 0.6703 - val_loss: 0.8498 - val_accuracy: 0.7826\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7803 - accuracy: 0.6813 - val_loss: 0.8471 - val_accuracy: 0.7826\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7604 - accuracy: 0.7143 - val_loss: 0.8425 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7595 - accuracy: 0.6813 - val_loss: 0.8458 - val_accuracy: 0.6522\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7619 - accuracy: 0.6154 - val_loss: 0.8499 - val_accuracy: 0.6522\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7611 - accuracy: 0.6154 - val_loss: 0.8461 - val_accuracy: 0.6522\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7574 - accuracy: 0.6264 - val_loss: 0.8396 - val_accuracy: 0.6957\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7559 - accuracy: 0.6703 - val_loss: 0.8395 - val_accuracy: 0.6957\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7446 - accuracy: 0.6593 - val_loss: 0.8407 - val_accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7514 - accuracy: 0.7033 - val_loss: 0.8418 - val_accuracy: 0.6957\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7426 - accuracy: 0.6264 - val_loss: 0.8493 - val_accuracy: 0.6957\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7420 - accuracy: 0.6264 - val_loss: 0.8513 - val_accuracy: 0.6957\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7434 - accuracy: 0.6484 - val_loss: 0.8452 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7372 - accuracy: 0.6593 - val_loss: 0.8445 - val_accuracy: 0.7826\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7256 - accuracy: 0.7033 - val_loss: 0.8465 - val_accuracy: 0.6957\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7146 - accuracy: 0.7033 - val_loss: 0.8599 - val_accuracy: 0.6957\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7340 - accuracy: 0.6484 - val_loss: 0.8526 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7314 - accuracy: 0.6593 - val_loss: 0.8489 - val_accuracy: 0.7826\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7203 - accuracy: 0.6813 - val_loss: 0.8506 - val_accuracy: 0.7391\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7398 - accuracy: 0.6703 - val_loss: 0.8544 - val_accuracy: 0.6957\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7338 - accuracy: 0.6813 - val_loss: 0.8515 - val_accuracy: 0.6957\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7222 - accuracy: 0.6703 - val_loss: 0.8473 - val_accuracy: 0.7826\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7280 - accuracy: 0.7033 - val_loss: 0.8465 - val_accuracy: 0.7391\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7063 - accuracy: 0.6923 - val_loss: 0.8581 - val_accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7108 - accuracy: 0.6813 - val_loss: 0.8460 - val_accuracy: 0.7391\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7153 - accuracy: 0.6484 - val_loss: 0.8388 - val_accuracy: 0.7826\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7280 - accuracy: 0.6923 - val_loss: 0.8457 - val_accuracy: 0.7391\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7144 - accuracy: 0.6813 - val_loss: 0.8415 - val_accuracy: 0.7826\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7089 - accuracy: 0.7033 - val_loss: 0.8349 - val_accuracy: 0.7826\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7055 - accuracy: 0.6703 - val_loss: 0.8351 - val_accuracy: 0.7826\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7096 - accuracy: 0.6484 - val_loss: 0.8574 - val_accuracy: 0.6957\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7002 - accuracy: 0.6813 - val_loss: 0.8474 - val_accuracy: 0.7826\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7127 - accuracy: 0.6923 - val_loss: 0.8426 - val_accuracy: 0.7826\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7432 - accuracy: 0.6593 - val_loss: 0.8884 - val_accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7105 - accuracy: 0.6484 - val_loss: 0.8573 - val_accuracy: 0.7826\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7115 - accuracy: 0.6813 - val_loss: 0.8523 - val_accuracy: 0.7826\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7184 - accuracy: 0.6593 - val_loss: 0.8600 - val_accuracy: 0.7826\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7087 - accuracy: 0.7033 - val_loss: 0.9008 - val_accuracy: 0.6957\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6953 - accuracy: 0.6703 - val_loss: 0.8628 - val_accuracy: 0.7826\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6871 - accuracy: 0.6923 - val_loss: 0.8638 - val_accuracy: 0.7826\n",
      "<keras.callbacks.History object at 0x7fe518392670>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Thermal Preference Accuracy: 0.6754385964912281\n",
      "Thermal Preference Weighted F1 Score: 0.6332743623765296\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Preference Model\")\n",
    "thermalpref_model = define_model_architecture(num_classes=3)\n",
    "thermalpref_model, thermalpref_scaler = train_model(thermalpref_model, \n",
    "                                                    thermalpref_train, \n",
    "                                                    model_name='cnnlstm_base_thermalpref_model', \n",
    "                                                    target_col='Thermal Preference', \n",
    "                                                    num_classes=3)\n",
    "\n",
    "thermalpref_eval = evaluate_model(thermalpref_model, \n",
    "                                  thermalpref_test, \n",
    "                                  thermalpref_scaler,\n",
    "                                  model_name='cnnlstm_base_thermalpref_model', \n",
    "                                  target_col='Thermal Preference')\n",
    "print(\"Thermal Preference Accuracy:\", thermalpref_eval['accuracy'])\n",
    "print(\"Thermal Preference Weighted F1 Score:\", thermalpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Acceptability Model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,842\n",
      "Trainable params: 937,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6992 - accuracy: 0.1978 - val_loss: 0.6867 - val_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6828 - accuracy: 0.8022 - val_loss: 0.6783 - val_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6687 - accuracy: 0.8022 - val_loss: 0.6678 - val_accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6491 - accuracy: 0.8022 - val_loss: 0.6563 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6224 - accuracy: 0.8022 - val_loss: 0.6489 - val_accuracy: 0.6957\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5886 - accuracy: 0.8022 - val_loss: 0.6642 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5553 - accuracy: 0.8022 - val_loss: 0.7391 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5459 - accuracy: 0.8022 - val_loss: 0.8247 - val_accuracy: 0.6957\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5668 - accuracy: 0.8022 - val_loss: 0.8156 - val_accuracy: 0.6957\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5595 - accuracy: 0.8022 - val_loss: 0.7581 - val_accuracy: 0.6957\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5402 - accuracy: 0.8022 - val_loss: 0.7016 - val_accuracy: 0.6957\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5310 - accuracy: 0.8022 - val_loss: 0.6634 - val_accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5272 - accuracy: 0.8022 - val_loss: 0.6446 - val_accuracy: 0.6957\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5309 - accuracy: 0.8022 - val_loss: 0.6363 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5312 - accuracy: 0.8022 - val_loss: 0.6355 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5258 - accuracy: 0.8022 - val_loss: 0.6384 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5203 - accuracy: 0.8022 - val_loss: 0.6461 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5136 - accuracy: 0.8022 - val_loss: 0.6592 - val_accuracy: 0.6957\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5103 - accuracy: 0.8022 - val_loss: 0.6753 - val_accuracy: 0.6957\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5080 - accuracy: 0.8022 - val_loss: 0.6874 - val_accuracy: 0.6957\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5087 - accuracy: 0.8022 - val_loss: 0.6891 - val_accuracy: 0.6957\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5085 - accuracy: 0.8022 - val_loss: 0.6795 - val_accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5061 - accuracy: 0.8022 - val_loss: 0.6621 - val_accuracy: 0.6957\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5006 - accuracy: 0.8022 - val_loss: 0.6418 - val_accuracy: 0.6957\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4973 - accuracy: 0.8022 - val_loss: 0.6234 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4947 - accuracy: 0.8022 - val_loss: 0.6094 - val_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4945 - accuracy: 0.8022 - val_loss: 0.5997 - val_accuracy: 0.6957\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4928 - accuracy: 0.8022 - val_loss: 0.5934 - val_accuracy: 0.6957\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4916 - accuracy: 0.8022 - val_loss: 0.5904 - val_accuracy: 0.6957\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4852 - accuracy: 0.8022 - val_loss: 0.5900 - val_accuracy: 0.6957\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4821 - accuracy: 0.8022 - val_loss: 0.5899 - val_accuracy: 0.6957\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4774 - accuracy: 0.8022 - val_loss: 0.5823 - val_accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4778 - accuracy: 0.8022 - val_loss: 0.5613 - val_accuracy: 0.6957\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4673 - accuracy: 0.8022 - val_loss: 0.5287 - val_accuracy: 0.6957\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4697 - accuracy: 0.8022 - val_loss: 0.5051 - val_accuracy: 0.6957\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4748 - accuracy: 0.8022 - val_loss: 0.5204 - val_accuracy: 0.6957\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4669 - accuracy: 0.8022 - val_loss: 0.5435 - val_accuracy: 0.6957\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4763 - accuracy: 0.8022 - val_loss: 0.5248 - val_accuracy: 0.6957\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4763 - accuracy: 0.8022 - val_loss: 0.4960 - val_accuracy: 0.6957\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4645 - accuracy: 0.8022 - val_loss: 0.4803 - val_accuracy: 0.6957\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4770 - accuracy: 0.7912 - val_loss: 0.5018 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4670 - accuracy: 0.8022 - val_loss: 0.5158 - val_accuracy: 0.6957\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4639 - accuracy: 0.8022 - val_loss: 0.5197 - val_accuracy: 0.6957\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4658 - accuracy: 0.8022 - val_loss: 0.5154 - val_accuracy: 0.6957\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4591 - accuracy: 0.8022 - val_loss: 0.4895 - val_accuracy: 0.6957\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4634 - accuracy: 0.8022 - val_loss: 0.4935 - val_accuracy: 0.6957\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4555 - accuracy: 0.8132 - val_loss: 0.5336 - val_accuracy: 0.6957\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4553 - accuracy: 0.8022 - val_loss: 0.5227 - val_accuracy: 0.6957\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4585 - accuracy: 0.8022 - val_loss: 0.4783 - val_accuracy: 0.6957\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4591 - accuracy: 0.7912 - val_loss: 0.4954 - val_accuracy: 0.6957\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4526 - accuracy: 0.8132 - val_loss: 0.5206 - val_accuracy: 0.6957\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4486 - accuracy: 0.8022 - val_loss: 0.4559 - val_accuracy: 0.6957\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4571 - accuracy: 0.8132 - val_loss: 0.4789 - val_accuracy: 0.6957\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4415 - accuracy: 0.8352 - val_loss: 0.4570 - val_accuracy: 0.6522\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4366 - accuracy: 0.8022 - val_loss: 0.4531 - val_accuracy: 0.6957\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4345 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.6957\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4637 - accuracy: 0.8022 - val_loss: 0.4291 - val_accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4198 - accuracy: 0.8242 - val_loss: 0.4247 - val_accuracy: 0.8261\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4206 - accuracy: 0.8462 - val_loss: 0.6175 - val_accuracy: 0.6957\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4632 - accuracy: 0.8022 - val_loss: 0.4282 - val_accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4252 - accuracy: 0.8132 - val_loss: 0.4046 - val_accuracy: 0.8696\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4259 - accuracy: 0.8132 - val_loss: 0.6337 - val_accuracy: 0.6957\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4504 - accuracy: 0.8132 - val_loss: 0.5777 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4622 - accuracy: 0.8022 - val_loss: 0.4540 - val_accuracy: 0.7826\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4700 - accuracy: 0.7582 - val_loss: 0.4521 - val_accuracy: 0.6957\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4143 - accuracy: 0.8022 - val_loss: 0.5402 - val_accuracy: 0.6522\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4443 - accuracy: 0.8132 - val_loss: 0.5073 - val_accuracy: 0.6522\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4278 - accuracy: 0.8022 - val_loss: 0.4289 - val_accuracy: 0.7391\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4387 - accuracy: 0.8242 - val_loss: 0.4109 - val_accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4211 - accuracy: 0.8242 - val_loss: 0.4377 - val_accuracy: 0.6957\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4161 - accuracy: 0.8462 - val_loss: 0.4958 - val_accuracy: 0.6522\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4487 - accuracy: 0.7802 - val_loss: 0.4853 - val_accuracy: 0.6522\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4141 - accuracy: 0.8352 - val_loss: 0.4303 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4301 - accuracy: 0.8132 - val_loss: 0.4105 - val_accuracy: 0.8696\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4205 - accuracy: 0.8022 - val_loss: 0.4072 - val_accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4315 - accuracy: 0.8022 - val_loss: 0.4566 - val_accuracy: 0.6522\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4073 - accuracy: 0.8132 - val_loss: 0.5307 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4501 - accuracy: 0.7912 - val_loss: 0.4750 - val_accuracy: 0.6522\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4130 - accuracy: 0.8462 - val_loss: 0.4187 - val_accuracy: 0.7826\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4247 - accuracy: 0.8022 - val_loss: 0.4063 - val_accuracy: 0.8696\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4361 - accuracy: 0.7912 - val_loss: 0.4036 - val_accuracy: 0.8696\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4218 - accuracy: 0.8132 - val_loss: 0.4722 - val_accuracy: 0.6522\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4134 - accuracy: 0.8132 - val_loss: 0.4727 - val_accuracy: 0.6522\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4050 - accuracy: 0.8242 - val_loss: 0.4095 - val_accuracy: 0.8696\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4190 - accuracy: 0.8022 - val_loss: 0.4129 - val_accuracy: 0.8696\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3943 - accuracy: 0.8462 - val_loss: 0.4037 - val_accuracy: 0.8696\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4092 - accuracy: 0.8132 - val_loss: 0.4369 - val_accuracy: 0.7826\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4072 - accuracy: 0.8132 - val_loss: 0.4460 - val_accuracy: 0.7391\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4165 - accuracy: 0.8462 - val_loss: 0.4010 - val_accuracy: 0.8696\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4172 - accuracy: 0.8022 - val_loss: 0.3982 - val_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4122 - accuracy: 0.8242 - val_loss: 0.4083 - val_accuracy: 0.8696\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4193 - accuracy: 0.8022 - val_loss: 0.4187 - val_accuracy: 0.8696\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4151 - accuracy: 0.8132 - val_loss: 0.4004 - val_accuracy: 0.8261\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - accuracy: 0.8242 - val_loss: 0.4124 - val_accuracy: 0.8696\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4149 - accuracy: 0.8022 - val_loss: 0.4157 - val_accuracy: 0.8696\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4258 - accuracy: 0.7912 - val_loss: 0.3992 - val_accuracy: 0.8696\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4167 - accuracy: 0.8242 - val_loss: 0.3975 - val_accuracy: 0.8696\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4155 - accuracy: 0.8132 - val_loss: 0.4195 - val_accuracy: 0.8696\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3980 - accuracy: 0.8022 - val_loss: 0.4525 - val_accuracy: 0.7391\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3962 - accuracy: 0.8132 - val_loss: 0.4594 - val_accuracy: 0.7391\n",
      "<keras.callbacks.History object at 0x7fe508d88f70>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Thermal Acceptability Accuracy: 0.8228070175438597\n",
      "Thermal Acceptability Weighted F1 Score: 0.8002772174474023\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal acceptability model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Acceptability Model\")\n",
    "thermalacc_model = define_model_architecture(num_classes=2)\n",
    "thermalacc_model, thermalacc_scaler = train_model(thermalacc_model, \n",
    "                                                  thermalacc_train, \n",
    "                                                  model_name='cnnlstm_base_thermalacc_model', \n",
    "                                                  target_col='Thermal Acceptability', \n",
    "                                                  num_classes=2)\n",
    "\n",
    "thermalacc_eval = evaluate_model(thermalacc_model, \n",
    "                                 thermalacc_test, \n",
    "                                 thermalacc_scaler,\n",
    "                                 model_name='cnnlstm_base_thermalacc_model', \n",
    "                                 target_col='Thermal Acceptability')\n",
    "print(\"Thermal Acceptability Accuracy:\", thermalacc_eval['accuracy'])\n",
    "print(\"Thermal Acceptability Weighted F1 Score:\", thermalacc_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Air Movement Preference Model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0975 - accuracy: 0.4945 - val_loss: 1.0847 - val_accuracy: 0.3913\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0738 - accuracy: 0.4945 - val_loss: 1.0669 - val_accuracy: 0.3913\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.0374 - accuracy: 0.4945 - val_loss: 1.0593 - val_accuracy: 0.3913\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0003 - accuracy: 0.4945 - val_loss: 1.0834 - val_accuracy: 0.3913\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9767 - accuracy: 0.4945 - val_loss: 1.1550 - val_accuracy: 0.3913\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9838 - accuracy: 0.4945 - val_loss: 1.1627 - val_accuracy: 0.3913\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9868 - accuracy: 0.4945 - val_loss: 1.1229 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9735 - accuracy: 0.4945 - val_loss: 1.0786 - val_accuracy: 0.3913\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9647 - accuracy: 0.4945 - val_loss: 1.0487 - val_accuracy: 0.3913\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9647 - accuracy: 0.4945 - val_loss: 1.0340 - val_accuracy: 0.3913\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9664 - accuracy: 0.4945 - val_loss: 1.0280 - val_accuracy: 0.3913\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9680 - accuracy: 0.4945 - val_loss: 1.0259 - val_accuracy: 0.3913\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9645 - accuracy: 0.4945 - val_loss: 1.0277 - val_accuracy: 0.3913\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9583 - accuracy: 0.4945 - val_loss: 1.0338 - val_accuracy: 0.3913\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9547 - accuracy: 0.4945 - val_loss: 1.0434 - val_accuracy: 0.3913\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9518 - accuracy: 0.4945 - val_loss: 1.0531 - val_accuracy: 0.3913\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9534 - accuracy: 0.4945 - val_loss: 1.0563 - val_accuracy: 0.3913\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9531 - accuracy: 0.4945 - val_loss: 1.0499 - val_accuracy: 0.3913\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9499 - accuracy: 0.4945 - val_loss: 1.0371 - val_accuracy: 0.3913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9475 - accuracy: 0.4945 - val_loss: 1.0228 - val_accuracy: 0.3913\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9458 - accuracy: 0.4945 - val_loss: 1.0107 - val_accuracy: 0.3913\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9461 - accuracy: 0.4945 - val_loss: 1.0028 - val_accuracy: 0.3913\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9449 - accuracy: 0.4945 - val_loss: 0.9986 - val_accuracy: 0.3913\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9440 - accuracy: 0.4945 - val_loss: 0.9970 - val_accuracy: 0.3913\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9418 - accuracy: 0.4945 - val_loss: 0.9983 - val_accuracy: 0.3913\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9392 - accuracy: 0.4945 - val_loss: 1.0006 - val_accuracy: 0.3913\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9393 - accuracy: 0.4945 - val_loss: 0.9980 - val_accuracy: 0.3913\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9383 - accuracy: 0.4945 - val_loss: 0.9872 - val_accuracy: 0.3913\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9357 - accuracy: 0.4945 - val_loss: 0.9705 - val_accuracy: 0.3913\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9349 - accuracy: 0.4945 - val_loss: 0.9565 - val_accuracy: 0.3913\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9351 - accuracy: 0.4945 - val_loss: 0.9501 - val_accuracy: 0.3913\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9365 - accuracy: 0.4945 - val_loss: 0.9528 - val_accuracy: 0.3913\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9342 - accuracy: 0.4945 - val_loss: 0.9613 - val_accuracy: 0.3913\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9343 - accuracy: 0.4945 - val_loss: 0.9592 - val_accuracy: 0.3913\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9369 - accuracy: 0.4945 - val_loss: 0.9440 - val_accuracy: 0.4783\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9336 - accuracy: 0.5275 - val_loss: 0.9391 - val_accuracy: 0.4783\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9330 - accuracy: 0.5495 - val_loss: 0.9476 - val_accuracy: 0.4348\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9327 - accuracy: 0.4615 - val_loss: 0.9542 - val_accuracy: 0.3913\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9315 - accuracy: 0.4835 - val_loss: 0.9510 - val_accuracy: 0.3913\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9341 - accuracy: 0.4945 - val_loss: 0.9450 - val_accuracy: 0.4348\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9342 - accuracy: 0.5165 - val_loss: 0.9423 - val_accuracy: 0.4783\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9311 - accuracy: 0.5385 - val_loss: 0.9441 - val_accuracy: 0.5217\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9324 - accuracy: 0.5165 - val_loss: 0.9500 - val_accuracy: 0.5217\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9306 - accuracy: 0.5275 - val_loss: 0.9575 - val_accuracy: 0.4783\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9292 - accuracy: 0.5165 - val_loss: 0.9654 - val_accuracy: 0.3913\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9296 - accuracy: 0.4945 - val_loss: 0.9632 - val_accuracy: 0.4348\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9286 - accuracy: 0.4945 - val_loss: 0.9571 - val_accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9275 - accuracy: 0.5275 - val_loss: 0.9557 - val_accuracy: 0.5217\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9301 - accuracy: 0.5165 - val_loss: 0.9574 - val_accuracy: 0.4783\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9285 - accuracy: 0.4835 - val_loss: 0.9588 - val_accuracy: 0.4783\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9247 - accuracy: 0.5495 - val_loss: 0.9595 - val_accuracy: 0.4348\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9268 - accuracy: 0.5714 - val_loss: 0.9560 - val_accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9274 - accuracy: 0.5604 - val_loss: 0.9521 - val_accuracy: 0.5217\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9275 - accuracy: 0.5275 - val_loss: 0.9498 - val_accuracy: 0.5217\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9283 - accuracy: 0.5165 - val_loss: 0.9480 - val_accuracy: 0.5217\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9261 - accuracy: 0.5055 - val_loss: 0.9495 - val_accuracy: 0.4783\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9273 - accuracy: 0.5165 - val_loss: 0.9484 - val_accuracy: 0.4348\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9259 - accuracy: 0.4945 - val_loss: 0.9430 - val_accuracy: 0.5217\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9273 - accuracy: 0.4945 - val_loss: 0.9380 - val_accuracy: 0.5217\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9205 - accuracy: 0.4945 - val_loss: 0.9428 - val_accuracy: 0.5217\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9216 - accuracy: 0.5275 - val_loss: 0.9503 - val_accuracy: 0.4348\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9211 - accuracy: 0.5055 - val_loss: 0.9485 - val_accuracy: 0.5217\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9253 - accuracy: 0.5275 - val_loss: 0.9441 - val_accuracy: 0.5217\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9168 - accuracy: 0.5275 - val_loss: 0.9445 - val_accuracy: 0.5217\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9183 - accuracy: 0.5055 - val_loss: 0.9482 - val_accuracy: 0.5217\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9154 - accuracy: 0.5275 - val_loss: 0.9490 - val_accuracy: 0.5217\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9139 - accuracy: 0.5495 - val_loss: 0.9455 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9146 - accuracy: 0.5165 - val_loss: 0.9419 - val_accuracy: 0.5217\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9121 - accuracy: 0.5055 - val_loss: 0.9427 - val_accuracy: 0.5217\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9117 - accuracy: 0.5165 - val_loss: 0.9469 - val_accuracy: 0.5217\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9118 - accuracy: 0.5055 - val_loss: 0.9403 - val_accuracy: 0.5217\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9078 - accuracy: 0.5385 - val_loss: 0.9408 - val_accuracy: 0.4783\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8964 - accuracy: 0.5275 - val_loss: 0.9448 - val_accuracy: 0.5217\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8993 - accuracy: 0.5165 - val_loss: 0.9358 - val_accuracy: 0.5217\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8908 - accuracy: 0.5275 - val_loss: 0.9325 - val_accuracy: 0.4783\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8918 - accuracy: 0.5714 - val_loss: 0.9350 - val_accuracy: 0.5217\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8895 - accuracy: 0.5604 - val_loss: 0.9380 - val_accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8727 - accuracy: 0.5275 - val_loss: 1.0033 - val_accuracy: 0.3478\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9270 - accuracy: 0.4945 - val_loss: 1.0039 - val_accuracy: 0.5217\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8898 - accuracy: 0.5275 - val_loss: 0.9689 - val_accuracy: 0.4783\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8738 - accuracy: 0.5165 - val_loss: 0.9313 - val_accuracy: 0.4348\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8723 - accuracy: 0.5824 - val_loss: 0.9545 - val_accuracy: 0.3043\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8781 - accuracy: 0.5055 - val_loss: 0.9812 - val_accuracy: 0.3913\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8743 - accuracy: 0.5714 - val_loss: 0.9851 - val_accuracy: 0.4783\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8738 - accuracy: 0.5714 - val_loss: 0.9549 - val_accuracy: 0.4783\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8694 - accuracy: 0.5495 - val_loss: 0.9562 - val_accuracy: 0.4783\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8642 - accuracy: 0.5495 - val_loss: 0.9639 - val_accuracy: 0.4348\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8664 - accuracy: 0.5385 - val_loss: 1.0058 - val_accuracy: 0.4348\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8528 - accuracy: 0.5824 - val_loss: 0.9881 - val_accuracy: 0.3913\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8627 - accuracy: 0.5275 - val_loss: 0.9603 - val_accuracy: 0.3913\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8556 - accuracy: 0.5714 - val_loss: 1.0040 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8541 - accuracy: 0.5385 - val_loss: 0.9902 - val_accuracy: 0.4783\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8444 - accuracy: 0.5495 - val_loss: 0.9533 - val_accuracy: 0.2609\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8633 - accuracy: 0.4945 - val_loss: 1.0377 - val_accuracy: 0.5217\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8561 - accuracy: 0.5714 - val_loss: 0.9649 - val_accuracy: 0.4783\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8261 - accuracy: 0.5604 - val_loss: 0.9310 - val_accuracy: 0.3478\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8435 - accuracy: 0.5604 - val_loss: 0.9622 - val_accuracy: 0.4783\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8278 - accuracy: 0.5824 - val_loss: 1.0092 - val_accuracy: 0.4783\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8278 - accuracy: 0.5934 - val_loss: 0.9306 - val_accuracy: 0.3913\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8280 - accuracy: 0.5714 - val_loss: 0.9601 - val_accuracy: 0.4348\n",
      "<keras.callbacks.History object at 0x7fe4fe173880>\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Air Movement Preference Accuracy: 0.5736842105263158\n",
      "Air Movement Preference Weighted F1 Score: 0.5372460316522274\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate air movement preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Air Movement Preference Model\")\n",
    "airpref_model = define_model_architecture(num_classes=3)\n",
    "airpref_model, airpref_scaler = train_model(airpref_model, \n",
    "                                            airpref_train, \n",
    "                                            model_name='cnnlstm_base_airpref_model', \n",
    "                                            target_col='Air Movement Preference', \n",
    "                                            num_classes=3)\n",
    "\n",
    "airpref_eval = evaluate_model(airpref_model, \n",
    "                              airpref_test, \n",
    "                              airpref_scaler,\n",
    "                              model_name='cnnlstm_base_airpref_model', \n",
    "                              target_col='Air Movement Preference')\n",
    "print(\"Air Movement Preference Accuracy:\", airpref_eval['accuracy'])\n",
    "print(\"Air Movement Preference Weighted F1 Score:\", airpref_eval['weighted_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
